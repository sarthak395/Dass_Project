{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarthak395/Dass_Project/blob/main/Memory/Memorymodelextract.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiPcBXB4IRFH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-FD7LclJBbp"
      },
      "outputs": [],
      "source": [
        "# LOADING DATA\n",
        "def load_data(input_file):\n",
        "    data = pd.read_csv(input_file)\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inputcols(input_dataset):\n",
        "    names = input_dataset['Name']\n",
        "    details = input_dataset['Details']\n",
        "    return names, details\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_data('memory.csv')\n",
        "names, details = inputcols(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_company_name(names,expression):\n",
        "    companylist_name = []\n",
        "    for name in names:\n",
        "        re_search = re.search(expression, name)\n",
        "        if re_search:\n",
        "            companylist_name.append(name)\n",
        "    return companylist_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_company_details(details,expression):\n",
        "    companylist_det = []\n",
        "    for det in details:\n",
        "        re_search = re.search(expression, det)\n",
        "        if re_search:\n",
        "            companylist_det.append(det)\n",
        "    return companylist_det;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filtering_company_products(names, details, expression):\n",
        "    companylist_name = extract_company_name(names, expression);\n",
        "    companylist_det = extract_company_details(details, expression);\n",
        "    companylist = pd.concat([pd.Series(companylist_name), pd.Series(companylist_det)], axis=1)\n",
        "    return companylist;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_company_model_data(companylist,model_expression,company_name):\n",
        "    companymodelnumbers = []\n",
        "\n",
        "    for name, det in companylist.itertuples(index=False):\n",
        "        re_search = re.search(model_expression, name)\n",
        "        if re_search:\n",
        "            companymodelnumbers.append({\"company\": company_name, \"name\": name, \"model\": re_search.group(0)})\n",
        "        else:\n",
        "            re_search2 = re.search(model_expression, det)\n",
        "            if re_search2:\n",
        "                companymodelnumbers.append({\"company\": company_name, \"name\": name, \"model\": re_search2.group(0)})\n",
        "            else:\n",
        "                companymodelnumbers.append({\"company\": company_name, \"name\": name, \"model\": np.nan})\n",
        "\n",
        "    # NOW CHECK\n",
        "\n",
        "    companymodelnumbers = pd.DataFrame(companymodelnumbers)\n",
        "    return companymodelnumbers;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhance_model_with_size (size_expression , company_model_data):\n",
        "    model_size = []\n",
        "    for company ,name, model in company_model_data.itertuples(index=False):\n",
        "        if pd.isnull(name):\n",
        "            model_size.append({\"name\": name,\"company\":company,\"model\":model, \"size\": np.nan})\n",
        "            continue\n",
        "        re_search = re.search(size_expression, name)\n",
        "        if re_search:\n",
        "            model_size.append({\"name\": name,\"company\":company,\"model\":model, \"size\": re_search.group(0)})\n",
        "        else:\n",
        "            model_size.append({\"name\": name,\"company\":company,\"model\":model, \"size\": np.nan})\n",
        "\n",
        "    model_size = pd.DataFrame(model_size)\n",
        "    company_model_with_size_data = pd.merge(company_model_data, model_size, on=['name','company','model'], how='inner')\n",
        "    return company_model_with_size_data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enhance_model_with_freq (freq_expression , company_model_data):\n",
        "    model_freq = []\n",
        "    for company,name, model in company_model_data.itertuples(index=False):\n",
        "        if pd.isnull(name) :\n",
        "            model_freq.append({\"name\": name,\"company\":company,\"model\":model, \"freq\": np.nan})\n",
        "            continue\n",
        "        re_search = re.search(freq_expression, name)\n",
        "        if re_search:\n",
        "            model_freq.append({\"name\": name,\"company\":company,\"model\":model, \"freq\": re_search.group(0)})\n",
        "        else:\n",
        "            model_freq.append({\"name\": name,\"company\":company,\"model\":model, \"freq\": np.nan})\n",
        "\n",
        "    model_freq = pd.DataFrame(model_freq)\n",
        "    company_model_with_freq_data = pd.merge(company_model_data, model_freq, on=['name','company','model'], how='left')\n",
        "    return company_model_with_freq_data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "def complete_enhanced_data(company_model_with_size_data,company_model_with_freq_data):\n",
        "    enhanced_data = pd.merge(company_model_with_size_data, company_model_with_freq_data, on=['name','company','model'], how='left')\n",
        "    return enhanced_data;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Company:\n",
        "    def __init__(self,expression,model_expression,names,details,company_name):\n",
        "        self.company_name = company_name\n",
        "        self.names = names;\n",
        "        self.details = details;\n",
        "        self.expression = expression;\n",
        "        self.model_expression = model_expression;\n",
        "        self.productlist = pd.DataFrame()\n",
        "        self.model_data = pd.DataFrame()\n",
        "        self.model_with_size = pd.DataFrame()\n",
        "        self.model_with_freq = pd.DataFrame()\n",
        "        self.enhanced_data = pd.DataFrame()\n",
        "     \n",
        "    def setcompanylist(self):\n",
        "        self.productlist = filtering_company_products(self.names, self.details, self.expression)\n",
        "    \n",
        "    def setmodel_data(self):\n",
        "        self.model_data = extract_company_model_data(self.productlist,self.model_expression,self.company_name)\n",
        "\n",
        "    def setmodel_with_size(self,size_expression):\n",
        "        self.model_with_size = enhance_model_with_size(size_expression,self.model_data)\n",
        "\n",
        "    def setmodel_with_freq(self,freq_expression):\n",
        "        self.model_with_freq = enhance_model_with_freq(freq_expression,self.model_data)\n",
        "        \n",
        "    def setenhanced_data(self):\n",
        "        self.enhanced_data = complete_enhanced_data(self.model_with_size,self.model_with_freq)\n",
        "    \n",
        "    def callall(self,size_expression,freq_expression):\n",
        "        self.setcompanylist()\n",
        "        self.setmodel_data()\n",
        "        self.setmodel_with_size(size_expression)\n",
        "        self.setmodel_with_freq(freq_expression)\n",
        "        self.setenhanced_data()\n",
        "        return self.enhanced_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "adata = Company('(?i)adata ' , '(AX4U|AD4U|AX4S)[A-Za-z0-9-]*( )?' , names , details , \"Adata\")\n",
        "crucial = Company('(?i)crucial ' , '(BL|CB|CT)[A-Za-z0-9-]*( )?' , names , details , \"Crucial\")\n",
        "corcair = Company('(?i)corsair ' , '(CMD|CMK|CMZ|CMW|CMT|CMV)[A-Za-z0-9-]*( )?' , names , details , \"Corcair\")\n",
        "gskill = Company('(?i)(g.skill) ' , '(F4-)[A-Za-z0-9-]*( )?' , names , details , \"Gskill\")\n",
        "antec = Company('(?i)(antec) ' , '(AM)[A-Za-z0-9-]*( )?' , names , details , \"Antec\")\n",
        "gigabyte =  Company('(?i)(gigabyte) ' , '(GP-)[A-Za-z0-9-]*( )?' , names , details , \"Gigabyte\")\n",
        "\n",
        "size_expression = '[0-9]{1,2}( )?GB( )?'\n",
        "freq_expression = '[0-9]{4}( )?(?i)MHz( )?'\n",
        "\n",
        "adata.callall(size_expression,freq_expression)\n",
        "crucial.callall(size_expression,freq_expression)\n",
        "corcair.callall(size_expression,freq_expression)\n",
        "gskill.callall(size_expression,freq_expression)\n",
        "antec.callall(size_expression,freq_expression)\n",
        "gigabyte.callall(size_expression,freq_expression)\n",
        "\n",
        "result = pd.concat([adata.enhanced_data,crucial.enhanced_data,corcair.enhanced_data,gskill.enhanced_data,antec.enhanced_data,gigabyte.enhanced_data] ,axis=0, ignore_index=True)\n",
        "\n",
        "result.to_csv('result.csv' , index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
